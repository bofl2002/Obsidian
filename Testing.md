[[Fokusomr√•der]]

**

## M√•l med testning

De prim√¶re m√•l med testning r√¶kker ud over blot at finde fejl:

- Find defekter f√∏r brugerne g√∏r - Fang problemer i kontrollerede milj√∏er frem for i produktion
    
- Verificer at krav er opfyldt - Sikr at softwaren g√∏r det, den skal
    
- Valid√©r brugerforventninger - Bekr√¶ft at softwaren l√∏ser rigtige brugerproblemer
    
- Vurd√©r kvalitet og risiko - Forst√• systemets stabilitet og p√•lidelighed
    
- Forhindre regressioner - Sikr at nye √¶ndringer ikke √∏del√¶gger eksisterende funktionalitet
    
- Opbyg tillid - Giv interessenter sikkerhed for at softwaren er klar til levering
    
- Forbedr udviklingsprocessen - Feedback fra testning hj√¶lper med at forfine kodepraksis og arkitektur
    

## Grunde til at du m√•ske ikke vil fjerne en bug

Modintutivt b√∏r ikke alle bugs rettes med det samme:

- Brugere er afh√¶ngige af opf√∏rslen - "Buggen" kan v√¶re blevet en funktion, man stoler p√•
    
- Rettelsen er mere risikabel end buggen - √Ündringer kan introducere mere alvorlige problemer
    
- Lav indvirkning, h√∏je omkostninger - Indsatsen for at rette opvejer ikke den minimale brugerindvirkning
    
- T√¶t p√• end-of-life - Produktet bliver snart udfaset alligevel
    
- Der findes workarounds - Brugere har brugbare alternativer, der virker
    
- Performance-afvejninger - Rettelsen kan forringe systemets ydeevne uacceptabelt
    
- Breaking API-√¶ndringer - Rettelsen ville bryde bagudkompatibilitet for integratorer
    
- Kun edge case - P√•virker et s√• sj√¶ldent scenarie, at ressourcer er bedre brugt andre steder
    
- Kompleks funktionsinteraktion - Buggen er dybt sammenflettet med andre systemer
    

## Hvordan man prioriterer bugs

Effektiv bug-prioritering overvejer typisk flere faktorer:

Alvorlighed √ó Hyppighed √ó Synlighed = Prioritet

N√∏gledimensioner at evaluere:

- Indvirkning p√• brugere - Blokerer det kritiske workflows? For√•rsager datatab? Skaber sikkerhedss√•rbarheder?
    
- Forekomstfrekvens - Hvor ofte vil brugere st√∏de p√• dette?
    
- Antal ber√∏rte brugere - Er det udbredt eller niche?
    
- Tilg√¶ngelighed af workaround - Kan brugere opn√• deres m√•l p√• en anden m√•de?
    
- Forretningsm√¶ssig indvirkning - P√•virker det oms√¶tning, omd√∏mme eller overholdelse?
    
- Kompleksitet og risiko ved rettelse - Kan vi rette det sikkert og hurtigt?
    

Almindelige prioritetsrammer:

- P0/Kritisk: Blokerer releases, for√•rsager datatab, sikkerhedsproblemer
    
- P1/H√∏j: St√∏rre funktionalitet √∏delagt, p√•virker mange brugere
    
- P2/Mellem: Moderat indvirkning, har workarounds
    
- P3/Lav: Mindre problemer, kosmetiske fejl
    

## Slags tests og testteknikker

### Typer efter omfang

Unit Testing - Test individuelle komponenter isoleret med mockede afh√¶ngigheder

Integrationstest - Verificer at flere komponenter fungerer korrekt sammen

Systemtest - Test det komplette integrerede system mod krav

End-to-End Test - Valid√©r hele workflows fra brugerperspektiv

Accepttest - Bekr√¶ft at systemet opfylder forretningskrav og er klar til deployment

**

- Unit test : Verificering
    
- Integration test : Verificering
    
- Regression test : Verificering
- 
- Automated testing: Verificering
    
- Component interface test: Verificering
    
- System testing: Verificering
    
- Acceptance testing : Validering
    

**

|**Unit test**| Tester individuelle kodeenheder (funktioner, metoder) mod deres design.|‚úÖ **Verificerende**|Sikrer, at koden virker som specificeret.|

|**Integration test**|Tester samspillet mellem moduler eller komponenter.|‚úÖ **Verificerende**|Tjekker at modulerne samarbejder korrekt ift. design.|

|**Regression test**|Tester at eksisterende funktionalitet stadig virker efter √¶ndringer.|‚úÖ **Verificerende**|Bekr√¶fter at systemet fortsat lever op til tidligere specifikationer.|

|**Automated testing**|En metode (ikke en testtype i sig selv), men bruges typisk til verificerende tests (unit, integration, regression).|‚úÖ **Oftest verificerende**|Automatisering af verificerende testprocesser.|

|**Component interface test**|Tester gr√¶nsefladerne mellem komponenter.|‚úÖ **Verificerende**|Tjekker at input/output passer til specifikationerne.|

|**System testing**|Tester hele systemet samlet mod kravspecifikationen.|‚öôÔ∏è **Prim√¶rt verificerende**, men kan have validerende elementer|Kontrollerer, at systemet lever op til kravene ‚Äî stadig mest teknisk.|

|**Acceptance testing**|Tester om systemet opfylder forretningsm√¶ssige krav og brugernes behov.|üí° **Validerende**|Bekr√¶fter, at systemet g√∏r det, kunden faktisk √∏nsker.|
### Typer efter tilgang

Funktionel testning - G√∏r det, hvad det skal?

- Black box testing (testning uden kendskab til intern kode)
    
- White box testing (testning med kendskab til implementering)
    
- Gray box testing (delvist kendskab)
    

Ikke-funktionel testning

- Performance-test (load, stress, spike, udholdenhed)
    
- Sikkerhedstest (penetration, s√•rbarhedsscanning)
    
- Brugbarhedstest
    
- Kompatibilitetstest (browsere, enheder, OS)
    
- Tilg√¶ngelighedstest
    

Regressionstest - Sikr at eksisterende funktionalitet stadig virker efter √¶ndringer

Smoke Testing - Hurtig verificering af at kritiske funktioner virker

Eksplorativ testning - Uscriptet unders√∏gelse for at opdage uventede problemer

### Testteknikker

√Ükvivalenspartitionering - Opdel input i grupper, der b√∏r opf√∏re sig ens

Boundary Value Analysis - Test ved kanterne af gyldige inputomr√•der

Decision Table Testing - Test kombinationer af betingelser systematisk

State Transition Testing - Verificer tilstands√¶ndringer i systemet

Error Guessing - Brug erfaring til at forudse hvor bugs kan gemme sig

Property-Based Testing - Gener√©r tilf√¶ldige input, der opfylder egenskaber

Mutation Testing - Introduc√©r bugs for at verificere at tests fanger dem

Fuzz Testing - Brug tilf√¶ldige/ugyldige input for at finde crashes og sikkerhedsproblemer

## Gode testvaner

For testdesign:

- Skriv tests f√∏r eller sammen med kode (Test-Driven Development)
    
- Test √©n ting pr. test - hold tests fokuserede og atomare
    
- Brug beskrivende testnavne, der forklarer hvad der testes
    
- F√∏lg Arrange-Act-Assert-m√∏nsteret
    
- Test b√•de happy paths og fejltilf√¶lde
    
- Test ikke kun hvad der virker - test hvad der b√∏r fejle
    

For testvedligeholdelse:

- Hold tests uafh√¶ngige - ingen test b√∏r afh√¶nge af en anden
    
- Undg√• skr√∏belige tests, der g√•r i stykker ved mindre UI-√¶ndringer
    
- G√∏r tests hurtige, s√• folk rent faktisk k√∏rer dem
    
- Fjern eller ret flaky tests med det samme
    
- Refaktor√©r tests, n√•r du refaktorerer kode
    
- Brug test fixtures og factories for at reducere duplikering
    

For testd√¶kning:

- Str√¶b efter h√∏j d√¶kning p√• kritiske paths, ikke 100% overalt
    
- Fokus√©r p√• forretningslogik frem for boilerplate
    
- Test edge cases og gr√¶nsetilstande
    
- Inklud√©r tests for rapporterede bugs for at forhindre regressioner
    
- Test fejlh√•ndtering og exception paths
    

Kulturelle vaner:

- Behandl testkode med samme omhu som produktionskode
    
- Gennemg√• tests i code reviews
    
- K√∏r tests hyppigt (CI/CD-integration)
    
- Commit ikke kode, der √∏del√¶gger tests
    
- Fejr n√•r tests fanger bugs
    
- Del interessante bugs og deres tests med teamet
    

## Metoder til at estimere antal bugs

At estimere tilbagev√¶rende bugs er i sagens natur usikkert, men der findes flere tilgange:

### Statistiske metoder

Capture-Recapture-metoden - Lad to uafh√¶ngige teams finde bugs. Overlap hj√¶lper med at estimere totale bugs.

- Formel: Totale Bugs ‚âà (Bugs fundet af Team A √ó Bugs fundet af Team B) / Bugs fundet af begge
    

Error Seeding - Inds√¶t bevidst kendte bugs, se derefter hvilken procent testere finder

- Hvis testere finder 80% af seedede bugs, har de sandsynligvis fundet ~80% af rigtige bugs
    

Bug Discovery Rate-analyse - Plot bugs fundet over tid. N√•r kurven flader ud, n√¶rmer du dig totalen.

### Empiriske metoder

Historiske data - Brug bug-densitet fra lignende tidligere projekter

- Bugs pr. KLOC (tusinde linjer kode)
    
- Bugs pr. funktionspoint
    
- Bugs pr. feature
    

Kodekompleksitetsm√•linger - Mere kompleks kode har tendens til at have flere bugs

- Cyklomatisk kompleksitet
    
- Coupling og cohesion-m√•linger
    
- Code churn rates
    

Defektforudsigelsesmodeller - Machine learning-modeller tr√¶net p√• historiske data

### Praktiske indikatorer

Diminishing Returns - N√•r testere k√¶mper for at finde nye bugs, er du t√¶t p√•

Testd√¶kning - H√∏jere kode/path-d√¶kning antyder f√¶rre skjulte bugs (men er ingen garanti)

Alvorlighedsfordeling - At finde kun lavt-alvorlige bugs antyder, at store er fundet

Uafh√¶ngige teamresultater - Lad et nyt team teste - hvis de finder f√• nye bugs, er du godt k√∏rende

### Tommelfingerregler

Branchegennemsnit antyder:

- Initial udvikling: 15-50 bugs pr. 1000 linjer kode
    
- Efter unit testing: 5-15 bugs pr. KLOC
    
- Efter systemtest: 0,5-3 bugs pr. KLOC
    
- Released software: 0,1-1 bugs pr. KLOC
    

Disse varierer enormt efter dom√¶ne - rumfart og medicinsk software har meget lavere rates, mens hurtige forbruger-apps kan have h√∏jere rates.

Vigtig advarsel: Disse metoder giver i bedste fald grove estimater. De er nyttige til planl√¶gning og ressourceallokering, men b√∏r ikke behandles som pr√¶cise forudsigelser. M√•let er ikke at finde hver eneste bug, men at finde bugs der betyder noget, f√∏r brugerne g√∏r.

**